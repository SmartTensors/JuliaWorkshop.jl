{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, Statistics, BSON, Zygote\n",
    "using Parameters: @with_kw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ! This is Work in Progress.. Focus is 1st on Code materials - lecture notes (markdown) to be added immediately after, only placeholders for now !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zygote gradients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = map(x -> 3x^2 + 2x + 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = gradient(x -> 3x^2 + 2x + 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "g (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g(x) = 5x^3 + 3x^2 + 2x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(g(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(g(1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 1;\n",
    "dg = gradient(x -> g(x),x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g'(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g''(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m;  @ /home/arvind/.julia/packages/Zygote/TaBlo/src/compiler/interface.jl:79 within `#48'\u001b[39m\n",
      "\u001b[95mdefine\u001b[39m \u001b[36mdouble\u001b[39m \u001b[93m@\"julia_#48_6790\"\u001b[39m\u001b[33m(\u001b[39m\u001b[36mdouble\u001b[39m \u001b[0m%0\u001b[33m)\u001b[39m \u001b[33m{\u001b[39m\n",
      "\u001b[91mtop:\u001b[39m\n",
      "\u001b[90m; ┌ @ /home/arvind/.julia/packages/Zygote/TaBlo/src/compiler/interface.jl:76 within `gradient'\u001b[39m\n",
      "\u001b[90m; │┌ @ /home/arvind/.julia/packages/Zygote/TaBlo/src/compiler/interface.jl:41 within `#46'\u001b[39m\n",
      "\u001b[90m; ││┌ @ In[4]:1 within `Pullback'\u001b[39m\n",
      "\u001b[90m; │││┌ @ /home/arvind/.julia/packages/ZygoteRules/OjfTt/src/adjoint.jl:59 within `#1817#back'\u001b[39m\n",
      "\u001b[90m; ││││┌ @ /home/arvind/.julia/packages/Zygote/TaBlo/src/lib/number.jl:6 within `#245'\u001b[39m\n",
      "\u001b[90m; │││││┌ @ promotion.jl:322 within `*' @ float.jl:332\u001b[39m\n",
      "        \u001b[0m%1 \u001b[0m= \u001b[96m\u001b[1mfmul\u001b[22m\u001b[39m \u001b[36mdouble\u001b[39m \u001b[0m%0\u001b[0m, \u001b[33m2.000000e+00\u001b[39m\n",
      "\u001b[90m; │││││└\u001b[39m\n",
      "\u001b[90m; │││││┌ @ float.jl:332 within `*'\u001b[39m\n",
      "        \u001b[0m%2 \u001b[0m= \u001b[96m\u001b[1mfmul\u001b[22m\u001b[39m \u001b[36mdouble\u001b[39m \u001b[0m%1\u001b[0m, \u001b[33m3.000000e+00\u001b[39m\n",
      "\u001b[90m; │││││└\u001b[39m\n",
      "\u001b[90m; │││││┌ @ intfuncs.jl:313 within `literal_pow'\u001b[39m\n",
      "\u001b[90m; ││││││┌ @ float.jl:332 within `*'\u001b[39m\n",
      "         \u001b[0m%3 \u001b[0m= \u001b[96m\u001b[1mfmul\u001b[22m\u001b[39m \u001b[36mdouble\u001b[39m \u001b[0m%0\u001b[0m, \u001b[0m%0\n",
      "\u001b[90m; │││││└└\u001b[39m\n",
      "\u001b[90m; │││││┌ @ promotion.jl:322 within `*' @ float.jl:332\u001b[39m\n",
      "        \u001b[0m%4 \u001b[0m= \u001b[96m\u001b[1mfmul\u001b[22m\u001b[39m \u001b[36mdouble\u001b[39m \u001b[0m%3\u001b[0m, \u001b[33m3.000000e+00\u001b[39m\n",
      "\u001b[90m; │││││└\u001b[39m\n",
      "\u001b[90m; │││││┌ @ float.jl:332 within `*'\u001b[39m\n",
      "        \u001b[0m%5 \u001b[0m= \u001b[96m\u001b[1mfmul\u001b[22m\u001b[39m \u001b[36mdouble\u001b[39m \u001b[0m%4\u001b[0m, \u001b[33m5.000000e+00\u001b[39m\n",
      "\u001b[90m; ││└└└└\u001b[39m\n",
      "\u001b[90m; ││┌ @ /home/arvind/.julia/packages/Zygote/TaBlo/src/lib/lib.jl:22 within `accum' @ /home/arvind/.julia/packages/Zygote/TaBlo/src/lib/lib.jl:17\u001b[39m\n",
      "\u001b[90m; │││┌ @ float.jl:326 within `+'\u001b[39m\n",
      "      \u001b[0m%6 \u001b[0m= \u001b[96m\u001b[1mfadd\u001b[22m\u001b[39m \u001b[36mdouble\u001b[39m \u001b[0m%2\u001b[0m, \u001b[33m2.000000e+00\u001b[39m\n",
      "      \u001b[0m%7 \u001b[0m= \u001b[96m\u001b[1mfadd\u001b[22m\u001b[39m \u001b[36mdouble\u001b[39m \u001b[0m%6\u001b[0m, \u001b[0m%5\n",
      "\u001b[90m; └└└└\u001b[39m\n",
      "  \u001b[96m\u001b[1mret\u001b[22m\u001b[39m \u001b[36mdouble\u001b[39m \u001b[0m%7\n",
      "\u001b[33m}\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@code_llvm g'(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = map((a,b) -> a^2 + b^2, 2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tuple{Int64, Int64}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (2,3)\n",
    "typeof(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vector{Int64} (alias for Array{Int64, 1})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = [2,3]\n",
    "typeof(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_diff = gradient((a,b) -> a^2 + b^2, 2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define as implicit function\n",
    "abfunc(a,b) = a^2 + b^2;\n",
    "out_diff2 = gradient((a,b) -> abfunc(a,b), 2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-0.01682912448487254, 0.35092026876742904, 0.5844391038001022], [-0.018791179106065214, 0.6608711873890442, 0.527195457877724])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define as explicit function\n",
    "# if a,b are arrays\n",
    "ainp = rand(3)\n",
    "binp = rand(3)\n",
    "cinp = rand(3)\n",
    "\n",
    "function abfuncE(a,b)\n",
    "    temp = a.^2 + b.^2\n",
    "    out = (cinp - temp).^2\n",
    "    return out\n",
    "end\n",
    "\n",
    "out_diff2 = gradient((a,b) -> sum(abfuncE(a,b)), ainp,binp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-1.8388029126611625 -1.8909131193676196 -1.270903504797593 -1.4087991139392744; 0.04240264844469612 -0.3007552618725052 0.027358374878052587 -0.18348267583440467; -1.1043498435027839 -0.6884639467539778 -0.918668035910722 -0.11885404542698645], [-0.7666143948576043 -0.5404682034873397 -0.4250911507581612; -0.49188630051413057 -0.11579571337120631 -0.4599633439177126; -1.006317074576978 -1.1208989239148213 -0.35184451879079354; -0.8370866894525162 -0.11493091647132882 -0.8288961312326126])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define as explicit function\n",
    "# if a,b are arrays\n",
    "ainp = rand(3,4)\n",
    "binp = rand(4,3)\n",
    "cinp = ones(3,3)\n",
    "\n",
    "function abfuncE(a,b)\n",
    "    temp = a * b\n",
    "    out = (cinp - temp).^2\n",
    "    return out\n",
    "end\n",
    "\n",
    "out_diff3 = gradient((a,b) -> sum(abfuncE(a,b)), ainp,binp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(out_diff3[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(out_diff3[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML\n",
    "consider y = w * x + b, which is standard gradient descent problem \n",
    "\n",
    "L = RMS(yhat - y)\n",
    "\n",
    "We need to compute dL/dw "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1: Using parameters as tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is [0.00334443227201436; 0.32591333255804367; 1.6725071823602882e-5; 0.13060259304603183]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.022574505611653167 -0.053296669141485245 -0.004632531415641356; 0.22284767567185307 0.5261261993308384 0.04573074051817141; 0.0015963975069865641 0.003768971565172808 0.00032759794301538307; -0.141069440871712 -0.3330540852346647 -0.028948966939405282], [-0.08178547880906928; 0.8073578296617228; 0.005783609914854715; -0.5110823672286725])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting constant random numbers\n",
    "using Random\n",
    "Random.seed!(1234)\n",
    "# define problem\n",
    "Wo = rand(4,3);\n",
    "bo = rand(4,1);\n",
    "x = rand(3);\n",
    "# Training data for Loss function definition\n",
    "yhat = rand(4);\n",
    "\n",
    "#Loss function\n",
    "function Loss(W,b)\n",
    "    y = W*x .+ b;\n",
    "    L = 0.5*(yhat - y).^2;\n",
    "    return L\n",
    "end\n",
    "\n",
    "L = Loss(Wo,bo);\n",
    "print(\"Loss is \", L)\n",
    "\n",
    "# Computing gradient w.r.t Loss\n",
    "dLdw = gradient((W,b) -> sum(Loss(W,b)), Wo,bo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×1 Matrix{Float64}:\n",
       " 0.7609281377774828\n",
       " 1.7578562368170239\n",
       " 0.9704533862969444\n",
       " 0.4346930380232398"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wo*x .+ bo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2: Using parameters as struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((W = [-0.022574505611653167 -0.053296669141485245 -0.004632531415641356; 0.22284767567185307 0.5261261993308384 0.04573074051817141; 0.0015963975069865641 0.003768971565172808 0.00032759794301538307; -0.141069440871712 -0.3330540852346647 -0.028948966939405282], b = [-0.08178547880906928; 0.8073578296617228; 0.005783609914854715; -0.5110823672286725]),)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct Weights\n",
    "    W\n",
    "    b\n",
    "end\n",
    "\n",
    "(l::Weights)(x) = 0.5*(yhat - (l.W*x .+ l.b)).^2;\n",
    "\n",
    "model = Weights(Wo, bo);\n",
    "\n",
    "dLdw2 = gradient(model -> sum(model(x)), model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2: Using parameters as dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.022574505611653167 -0.053296669141485245 -0.004632531415641356; 0.22284767567185307 0.5261261993308384 0.04573074051817141; 0.0015963975069865641 0.003768971565172808 0.00032759794301538307; -0.141069440871712 -0.3330540852346647 -0.028948966939405282][-0.08178547880906928; 0.8073578296617228; 0.005783609914854715; -0.5110823672286725]"
     ]
    }
   ],
   "source": [
    "linearfunc(θ,x) = 0.5*(yhat - (θ[:W]*x .+ θ[:b])).^2;\n",
    "\n",
    "θ = Dict(:W => Wo, :b => bo)\n",
    "\n",
    "dθ = gradient(θ -> sum(linearfunc(θ,x)), θ)\n",
    "print(dθ[1][:W])\n",
    "print(dθ[1][:b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zygote Gradients _Using Flux layers_\n",
    "same linear layer as above, but now with flux pre-defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearlayer = Dense(3,4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense(3, 4)         \u001b[90m# 16 parameters\u001b[39m"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       "  0.06093493508794132\n",
       " -0.39143472265048\n",
       "  0.07506218364123313\n",
       " -0.40533673770076334"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = linearlayer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Params([Float32[-0.03939439 0.18283667 -0.8357598; 0.23633786 -0.6694229 -0.3606828; -0.50153035 0.40500325 -0.89034; -0.6558338 -0.38946676 0.5206107], Float32[0.0, 0.0, 0.0, 0.0]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = Flux.params(linearlayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×3 Matrix{Float32}:\n",
       " -0.0393944   0.182837  -0.83576\n",
       "  0.236338   -0.669423  -0.360683\n",
       " -0.50153     0.405003  -0.89034\n",
       " -0.655834   -0.389467   0.520611"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is: 5.028868123612399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Grads(...)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# backprop thru this layer\n",
    "function loss(x, yhat)\n",
    "  y = linearlayer(x)\n",
    "  sum((yhat .- y).^2)\n",
    "end\n",
    "\n",
    "l = loss(x,yhat)\n",
    "println(\"loss is: \", l)\n",
    "gs = gradient(() -> loss(x,yhat), params(linearlayer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Zygote.Grads"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Params([Float32[-0.03939439 0.18283667 -0.8357598; 0.23633786 -0.6694229 -0.3606828; -0.50153035 0.40500325 -0.89034; -0.6558338 -0.38946676 0.5206107], Float32[0.0, 0.0, 0.0, 0.0]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KeySet for a IdDict{Any, Any} with 4 entries. Keys:\n",
       "  :(Main.yhat)\n",
       "  Float32[-0.03939439 0.18283667 -0.8357598; 0.23633786 -0.6694229 -0.3606828; …\n",
       "  :(Main.x)\n",
       "  Float32[0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys(gs.grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Params([Float32[-0.03939439 0.18283667 -0.8357598; 0.23633786 -0.6694229 -0.3606828; -0.50153035 0.40500325 -0.89034; -0.6558338 -0.38946676 0.5206107], Float32[0.0, 0.0, 0.0, 0.0]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#another way to computing gradients\n",
    "ps = params(linearlayer)\n",
    "gs2 = gradient(ps) do \n",
    "       loss(x,yhat)\n",
    "end\n",
    "typeof(gs)\n",
    "gs.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.4315745897572264 -1.0189143680865171 -0.08856374884289087; -0.7408033164416622 -1.7489795760986728 -0.1520208103452676; -0.49110066693821863 -1.1594508518254196 -0.10077914028200573; -0.7458705163116477 -1.76094284473411 -0.15306065427323046]\n",
      "[-1.5635573629972215, -2.683866259611562, -1.7792151854817133, -2.702224285905351]\n"
     ]
    }
   ],
   "source": [
    "for p in params(linearlayer)\n",
    "    println(gs[p])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: Float32[-0.03939439 0.18283667 -0.8357598; 0.23633786 -0.6694229 -0.3606828; -0.50153035 0.40500325 -0.89034; -0.6558338 -0.38946676 0.5206107]\n",
      "loss before: 5.028868123612399\n",
      "after: Float32[0.0037630692 0.2847281 -0.82690346; 0.3104182 -0.49452496 -0.3454807; -0.4524203 0.52094835 -0.8802621; -0.58124673 -0.21337248 0.53591675]\n",
      "loss after: 4.066032355256153\n",
      "before: Float32[0.0, 0.0, 0.0, 0.0]\n",
      "loss before: 4.066032355256153\n",
      "after: Float32[0.15635574, 0.26838663, 0.17792152, 0.27022243]\n",
      "loss after: 2.458428801436127\n"
     ]
    }
   ],
   "source": [
    "opt = ADAM()\n",
    "α = 0.1 #learning rate\n",
    "for p in params(linearlayer)\n",
    "    println(\"before: \", p)\n",
    "    println(\"loss before: \", loss(x,yhat))\n",
    "    Flux.Optimise.update!(p,α * gs[p])\n",
    "    println(\"after: \", p)\n",
    "    println(\"loss after: \", loss(x,yhat))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: Float32[0.0037630692 0.2847281 -0.82690346; 0.3104182 -0.49452496 -0.3454807; -0.4524203 0.52094835 -0.8802621; -0.58124673 -0.21337248 0.53591675]\n",
      "loss before: 2.458428801436127\n",
      "after: Float32[0.046920527 0.38661954 -0.8180471; 0.3844985 -0.319627 -0.33027864; -0.40331024 0.63689345 -0.8701842; -0.5066597 -0.037278198 0.5512228]\n",
      "loss after: 1.8006002770938272\n",
      "before: Float32[0.15635574, 0.26838663, 0.17792152, 0.27022243]\n",
      "loss before: 1.8006002770938272\n",
      "after: Float32[0.31271148, 0.53677326, 0.35584304, 0.54044485]\n",
      "loss after: 0.7980951557392415\n"
     ]
    }
   ],
   "source": [
    "# Easier way of updating\n",
    "opt = Descent(0.1) # Gradient descent with learning rate 0.1\n",
    "\n",
    "for p in params(linearlayer)\n",
    "    println(\"before: \", p) \n",
    "    println(\"loss before: \", loss(x,yhat))\n",
    "    Flux.Optimise.update!(opt, p, gs[p])\n",
    "    println(\"after: \", p)\n",
    "    println(\"loss after: \", loss(x,yhat))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zygote Internals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.479425538604203, Zygote.var\"#46#47\"{Zygote.ZBack{ChainRules.var\"#sin_pullback#1077\"{Float64}}}(Zygote.ZBack{ChainRules.var\"#sin_pullback#1077\"{Float64}}(ChainRules.var\"#sin_pullback#1077\"{Float64}(0.8775825618903728))))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, back = Zygote.pullback(sin,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.479425538604203"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8775825618903728,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8775825618903728"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying backprop thru arbitrary layers\n",
    "## 1. FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.5681775741557797, 0.18202604677360879, 0.03501885108907654, 0.18202604677360879]\n",
      "loss is: 6.66302933573632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Grads(...)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Random\n",
    "using FFTW\n",
    "Random.seed!(1234)\n",
    "# define problem\n",
    "x = rand(3);\n",
    "# Training data for Loss function definition\n",
    "yhat = rand(4);\n",
    "linearlayer = Dense(3,4,σ);\n",
    "model = Chain(linearlayer,x -> real(fft(x)));\n",
    "#model = Chain(linearlayer,x -> imag(fft(x)));\n",
    "out = model(x)\n",
    "println(out)\n",
    "\n",
    "# backprop thru this layer\n",
    "function loss(x)\n",
    "  y = model(x)\n",
    "  sum((y).^2)\n",
    "end\n",
    "\n",
    "l = loss(x)\n",
    "println(\"loss is: \", l)\n",
    "gs = gradient(() -> loss(x), params(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(out) = (8,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Grads(...)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Random\n",
    "using LinearAlgebra\n",
    "Random.seed!(1234)\n",
    "# define problem\n",
    "x = rand(3);\n",
    "xmat = Float32.(rand(10,10,1,1)); #conv input (w,l,nch,batch)\n",
    "yhatmat = Float32.(rand(10,10,1,1));\n",
    "# Training data for Loss function definition\n",
    "yhat = rand(4);\n",
    "linearlayer = Dense(3,4,σ);\n",
    "convlayer = Conv((3,3), 1 => 1, relu);\n",
    "#model = Chain(linearlayer,x -> svd(x));\n",
    "#model  = Chain(convlayer);\n",
    "model = Chain(convlayer,\n",
    "            x -> dropdims(x; dims=4),\n",
    "            x -> dropdims(x; dims=3),\n",
    "            x -> svd(x).S,\n",
    "            x -> x.^3 + 2*x);\n",
    "out = model(xmat);\n",
    "@show size(out)\n",
    "\n",
    "# backprop thru this layer\n",
    "function loss(x)\n",
    "  y = model(x)\n",
    "  sum((y).^2)\n",
    "end\n",
    "\n",
    "l = loss(xmat)\n",
    "#println(\"loss is: \", l)\n",
    "gs = gradient(() -> loss(xmat), params(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So adding SVD works.. although we have to drop dimensions and then add dimensions\n",
    "every iteration for it to work (since SVD only accepts a m x n matrix that can't have channel and nbatches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. NNs with Arbitrary equations embedded\n",
    "Lets consider input X matrix.\n",
    "Define output Y which satisfies Y = X' + 2X.^2 \n",
    "Problem: We have Y, but need to learn X such that the equation is satisfied.\n",
    "\n",
    "This works, as amply demonstrated in documentation and my own experiments. Just find a good application problem to use it with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(out) = (10, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Grads(...)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Random\n",
    "using LinearAlgebra\n",
    "Random.seed!(1234)\n",
    "# define problem\n",
    "x = rand(3);\n",
    "dx = 0.1;\n",
    "xmat = Float32.(rand(10,10,1,1)); #conv input (w,l,nch,batch)\n",
    "yhatmat = Float32.(rand(10,10,1,1));\n",
    "# Training data for Loss function definition\n",
    "yhat = rand(4);\n",
    "linearlayer = Dense(3,4,σ);\n",
    "convlayer = Conv((3,3), 1 => 1, pad=1, relu);\n",
    "\n",
    "function fdmlayer(x)\n",
    "    fdmgradx = (x[2:end,:] - x[1:end-1,:])/(2*dx);\n",
    "    fdmgrady = (x[:,2:end] - x[:,1:end-1])/(2*dx);\n",
    "    gradfull = fdmgradx' * fdmgrady'\n",
    "    #res = gradfull + 2 * x.^2\n",
    "    return gradfull\n",
    "end\n",
    "\n",
    "model = Chain(convlayer,\n",
    "            x -> dropdims(x, dims=4),\n",
    "            x -> dropdims(x, dims=3),\n",
    "            #x -> fdmlayer(x),\n",
    "            x -> x.^3 + 2*x);\n",
    "out = model(xmat);\n",
    "@show size(out)\n",
    "\n",
    "# backprop thru this layer\n",
    "function loss(x)\n",
    "  y = model(x)\n",
    "  sum((y).^2)\n",
    "end\n",
    "\n",
    "l = loss(xmat)\n",
    "#println(\"loss is: \", l)\n",
    "gs = gradient(() -> loss(xmat), params(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdmgradx = (xmat[2:end,:] - xmat[1:end-1,:])/(2*dx);\n",
    "fdmgrady = (xmat[:,2:end] - xmat[:,1:end-1])/(2*dx);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = fdmgradx' * fdmgrady'\n",
    "size(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = map((x) -> x.^3 + 2*x, out);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1367400223666475e10"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((out2).^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoiding Mutating Arrays with Zygote.Buffer\n",
    "(In Progress)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "Mutating arrays is not supported -- called setindex!(::Vector{Float64}, _...)",
     "output_type": "error",
     "traceback": [
      "Mutating arrays is not supported -- called setindex!(::Vector{Float64}, _...)",
      "",
      "Stacktrace:",
      "  [1] error(s::String)",
      "    @ Base ./error.jl:33",
      "  [2] (::Zygote.var\"#438#439\"{Vector{Float64}})(#unused#::Nothing)",
      "    @ Zygote ~/.julia/packages/Zygote/TaBlo/src/lib/array.jl:76",
      "  [3] (::Zygote.var\"#2341#back#440\"{Zygote.var\"#438#439\"{Vector{Float64}}})(Δ::Nothing)",
      "    @ Zygote ~/.julia/packages/ZygoteRules/OjfTt/src/adjoint.jl:59",
      "  [4] Pullback",
      "    @ ~/.julia/packages/Wavelets/AIqi0/src/mod/transforms_filter.jl:367 [inlined]",
      "  [5] (::typeof(∂(filtdown!)))(Δ::Nothing)",
      "    @ Zygote ~/.julia/packages/Zygote/TaBlo/src/compiler/interface2.jl:0",
      "  [6] Pullback",
      "    @ ~/.julia/packages/Wavelets/AIqi0/src/mod/transforms_filter.jl:50 [inlined]",
      "  [7] (::typeof(∂(_dwt!)))(Δ::FillArrays.Fill{Float64, 1, Tuple{Base.OneTo{Int64}}})",
      "    @ Zygote ~/.julia/packages/Zygote/TaBlo/src/compiler/interface2.jl:0",
      "  [8] Pullback",
      "    @ ~/.julia/packages/Wavelets/AIqi0/src/mod/transforms_filter.jl:24 [inlined]",
      "  [9] (::typeof(∂(_dwt!)))(Δ::FillArrays.Fill{Float64, 1, Tuple{Base.OneTo{Int64}}})",
      "    @ Zygote ~/.julia/packages/Zygote/TaBlo/src/compiler/interface2.jl:0",
      " [10] Pullback",
      "    @ ~/.julia/packages/Wavelets/AIqi0/src/mod/transforms_filter.jl:18 [inlined]",
      " [11] (::typeof(∂(_dwt!)))(Δ::FillArrays.Fill{Float64, 1, Tuple{Base.OneTo{Int64}}})",
      "    @ Zygote ~/.julia/packages/Zygote/TaBlo/src/compiler/interface2.jl:0",
      " [12] Pullback",
      "    @ ~/.julia/packages/Wavelets/AIqi0/src/mod/Transforms.jl:117 [inlined]",
      " [13] (::typeof(∂(dwt)))(Δ::FillArrays.Fill{Float64, 1, Tuple{Base.OneTo{Int64}}})",
      "    @ Zygote ~/.julia/packages/Zygote/TaBlo/src/compiler/interface2.jl:0",
      " [14] Pullback",
      "    @ ~/.julia/packages/Wavelets/AIqi0/src/mod/Transforms.jl:116 [inlined]",
      " [15] (::typeof(∂(dwt)))(Δ::FillArrays.Fill{Float64, 1, Tuple{Base.OneTo{Int64}}})",
      "    @ Zygote ~/.julia/packages/Zygote/TaBlo/src/compiler/interface2.jl:0",
      " [16] Pullback",
      "    @ ./In[82]:13 [inlined]",
      " [17] (::typeof(∂(bufmodel2)))(Δ::FillArrays.Fill{Float64, 1, Tuple{Base.OneTo{Int64}}})",
      "    @ Zygote ~/.julia/packages/Zygote/TaBlo/src/compiler/interface2.jl:0",
      " [18] Pullback",
      "    @ ./In[82]:17 [inlined]",
      " [19] (::Zygote.var\"#46#47\"{typeof(∂(#57))})(Δ::Float64)",
      "    @ Zygote ~/.julia/packages/Zygote/TaBlo/src/compiler/interface.jl:41",
      " [20] gradient(::Function, ::Vector{Float64}, ::Vararg{Vector{Float64}, N} where N)",
      "    @ Zygote ~/.julia/packages/Zygote/TaBlo/src/compiler/interface.jl:76",
      " [21] top-level scope",
      "    @ In[82]:17",
      " [22] eval",
      "    @ ./boot.jl:360 [inlined]",
      " [23] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "x = rand(10);\n",
    "\n",
    "function bufmodel(x)\n",
    "    buf = Zygote.Buffer(x,length(x))\n",
    "    for i=1:length(x)\n",
    "        buf[i] = x[i]\n",
    "    end\n",
    "    return copy(buf)\n",
    "end\n",
    "\n",
    "function bufmodel2(x)\n",
    "    buf = Zygote.Buffer(x,length(x));\n",
    "    buf = Wavelets.dwt(x,wavelet(WT.coif6));\n",
    "    return copy(buf)\n",
    "end\n",
    "\n",
    "gs = gradient(x -> sum(bufmodel2(x)), x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
